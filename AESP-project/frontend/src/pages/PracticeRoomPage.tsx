import { v4 as uuidv4 } from 'uuid';
import React, { useEffect, useRef, useState } from 'react';
import { Button, Card, Input, message, Typography, Space } from 'antd';
import { AudioOutlined, SendOutlined, DownCircleOutlined, CommentOutlined, BulbOutlined } from '@ant-design/icons';
import axiosClient from '../api/axiosClient';

// Import thÆ° viá»‡n ghi Ã¢m
import { MediaRecorder as ExtendableMediaRecorder, register } from 'extendable-media-recorder';
import { connect } from 'extendable-media-recorder-wav-encoder';

const { TextArea } = Input;

type Message = {
  id: string;
  from: 'user' | 'ai' | 'system';
  text: string;
};

export default function PracticeRoomPage() {
  const [messages, setMessages] = useState<Message[]>([]);
  const [input, setInput] = useState('');
  const [recording, setRecording] = useState(false);
  const [transcribing, setTranscribing] = useState(false);
  const [lastAssessment, setLastAssessment] = useState<any | null>(null);
  const [autoMode, setAutoMode] = useState(false);
  
  // ğŸ‘‡ State má»›i: LÆ°u cÃ¢u máº«u mÃ  AI Ä‘á» xuáº¥t
  const [targetSentence, setTargetSentence] = useState<string>('');
  
  // ğŸ‘‡ State má»›i: LÆ°u lá»‹ch sá»­ táº¥t cáº£ cÃ¢u máº«u Ä‘Ã£ dÃ¹ng
  const [sentenceHistory, setSentenceHistory] = useState<string[]>([]);

  const mediaRecorderRef = useRef<any>(null); 
  const mediaStreamRef = useRef<MediaStream | null>(null);
  const chunksRef = useRef<Blob[]>([]);

  useEffect(() => {
    const initWavEncoder = async () => {
        try { await register(await connect()); } catch (e) { }
    };
    initWavEncoder();

    setMessages([
      { id: 'welcome', from: 'system', text: 'ChÃ o má»«ng! Báº¥m "Láº¥y máº«u cÃ¢u" Ä‘á»ƒ AI ra Ä‘á» bÃ i cho báº¡n Ä‘á»c.' },
    ]);

    return () => {
      if (mediaStreamRef.current) mediaStreamRef.current.getTracks().forEach((t) => t.stop());
      window.speechSynthesis.cancel();
    };
  }, []);

  const appendMessage = (m: Message) => setMessages((prev) => [...prev, m]);

  const speak = (text: string, onEndCallback?: () => void) => {
    try {
      if ('speechSynthesis' in window) {
        window.speechSynthesis.cancel();
        const ut = new SpeechSynthesisUtterance(text);
        ut.lang = 'en-US';
        ut.onend = () => { if (onEndCallback) onEndCallback(); };
        ut.onerror = () => { if (onEndCallback) onEndCallback(); };
        window.speechSynthesis.speak(ut);
      } else {
        if (onEndCallback) onEndCallback();
      }
    } catch (e) {
      if (onEndCallback) onEndCallback();
    }
  };

  // ğŸ‘‡ HÃ m má»›i: Xin AI má»™t cÃ¢u máº«u (dÃ¹ng endpoint tá»‘i Æ°u /sentences/practice)
  const getSampleSentence = async () => {
    const typingId = 'typing';
    appendMessage({ id: typingId, from: 'system', text: 'AI Ä‘ang tÃ¬m máº«u cÃ¢u...' });

    try {
        // Gá»i endpoint sentence service (DB cache + AI fallback)
        // Truyá»n sentenceHistory Ä‘á»ƒ trÃ¡nh láº·p láº¡i cÃ¡c cÃ¢u trÆ°á»›c
        const response = await axiosClient.get('/sentences/practice', {
            params: { 
                topic: 'Daily life', 
                level: 'BEGINNER',
                forceAI: false, // DÃ¹ng cache DB náº¿u cÃ³
                excludedSentences: sentenceHistory.join('|||') // TrÃ¡nh láº·p láº¡i cÃ¢u trÆ°á»›c
            }
        });
        const sentence = response.data.sentence;
        const source = response.data.source;
        
        setMessages((prev) => prev.filter((m) => m.id !== typingId));
        
        // LÆ°u cÃ¢u máº«u vÃ o state Ä‘á»ƒ lÃ¡t ná»¯a cháº¥m Ä‘iá»ƒm
        setTargetSentence(sentence);
        
        // ThÃªm cÃ¢u vÃ o lá»‹ch sá»­
        setSentenceHistory((prev) => [...prev, sentence]);
        
        const sourceText = source === 'AI' ? ' (má»›i táº¡o)' : ' (tá»« kho)';
        appendMessage({ id: uuidv4(), from: 'ai', text: `ğŸ“– HÃ£y Ä‘á»c cÃ¢u nÃ y: "${sentence}"${sourceText}` });
        speak(sentence); // AI Ä‘á»c máº«u trÆ°á»›c

    } catch (e) {
        console.error(e);
        setMessages((prev) => prev.filter((m) => m.id !== typingId));
        message.error("Lá»—i khi láº¥y máº«u cÃ¢u.");
    }
  };

  const sendText = async (txt: string) => {
    if (!txt || txt.trim() === '') return;
    const content = txt.trim();
    
    appendMessage({ id: uuidv4(), from: 'user', text: content });
    setInput('');

    const typingId = 'typing';
    appendMessage({ id: typingId, from: 'system', text: 'AI Ä‘ang pháº£n há»“i...' });

    try {
      const response = await axiosClient.post('/chat/ask', { message: content });
      const aiText = response.data || '...';

      setMessages((prev) => prev.filter((m) => m.id !== typingId));
      appendMessage({ id: uuidv4(), from: 'ai', text: aiText });
      
      speak(aiText, () => {
        if (autoMode) {
          setTimeout(() => startLiveRecognition(), 500);
        }
      });

    } catch (err: any) {
      setMessages((prev) => prev.filter((m) => m.id !== typingId));
      if (autoMode) setAutoMode(false);
    }
  };

  const startLiveRecognition = () => {
    const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
    if (!SpeechRecognition) return;
    
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') return; 

    const rec = new SpeechRecognition();
    rec.lang = 'en-US';
    rec.interimResults = false;
    rec.maxAlternatives = 1;

    rec.onstart = () => setRecording(true);
    
    rec.onresult = (event: any) => {
      const text = event.results[0][0].transcript;
      sendText(text);
    };

    rec.onerror = (e: any) => {
      if (e.error === 'no-speech' && autoMode) setAutoMode(false);
      setRecording(false);
    };

    rec.onend = () => setRecording(false);
    rec.start();
  };

  const handleRecordedBlob = async (blob: Blob) => {
    try {
        setTranscribing(true);
        const form = new FormData();
        form.append('file', blob, 'record.wav'); 
        
        // 1. Transcribe
        const res = await axiosClient.post('/speech/transcribe', form, { 
             headers: { 'Content-Type': 'multipart/form-data' },
        });
        const transcribed: string = res.data;
        
        appendMessage({ id: uuidv4(), from: 'user', text: transcribed });
        
        // 2. Cháº¥m Ä‘iá»ƒm (Assess)
        const assessForm = new FormData();
        assessForm.append('file', blob, 'record.wav');
        
        // ğŸ‘‡ QUAN TRá»ŒNG: Náº¿u cÃ³ cÃ¢u máº«u (targetSentence), gá»­i nÃ³ lÃªn Ä‘á»ƒ so sÃ¡nh
        // Náº¿u khÃ´ng cÃ³, dÃ¹ng chÃ­nh vÄƒn báº£n nháº­n diá»‡n Ä‘Æ°á»£c (transcribed) Ä‘á»ƒ tá»± cháº¥m chÃ­nh nÃ³
        const referenceText = targetSentence && targetSentence.length > 0 ? targetSentence : transcribed;
        assessForm.append('text', referenceText);
        
        const assessRes = await axiosClient.post('/speech/assess', assessForm, {
            headers: { 'Content-Type': 'multipart/form-data' },
        });

        const assessment = assessRes.data;
        setLastAssessment(assessment);
        
        let feedbackMsg = `ğŸ¯ Äiá»ƒm: ${assessment.overallScore?.toFixed(0)}/100`;
        if (targetSentence) {
            feedbackMsg += ` (So vá»›i máº«u: "${targetSentence}")`;
            // Reset cÃ¢u máº«u sau khi cháº¥m xong Ä‘á»ƒ láº§n sau nÃ³i tá»± do
            setTargetSentence(''); 
        }

        appendMessage({
            id: uuidv4(),
            from: 'system',
            text: feedbackMsg,
        });

        // Náº¿u khÃ´ng pháº£i Ä‘ang luyá»‡n máº«u cÃ¢u thÃ¬ má»›i gá»­i cho Chat AI tráº£ lá»i tiáº¿p
        if (!targetSentence) {
             await sendText(transcribed);
        }

    } catch (e) {
        console.error(e);
        message.error('Lá»—i xá»­ lÃ½ audio.');
    } finally {
        setTranscribing(false);
    }
  };

  const startRecordingWav = async () => {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        mediaStreamRef.current = stream;
        const mr = new ExtendableMediaRecorder(stream, { mimeType: 'audio/wav' });
        chunksRef.current = [];
        mr.ondataavailable = (e: any) => { if (e.data.size > 0) chunksRef.current.push(e.data); };
        mr.onstop = async () => { 
            setRecording(false); 
            const blob = new Blob(chunksRef.current, { type: 'audio/wav' }); 
            await handleRecordedBlob(blob); 
        };
        mr.start();
        mediaRecorderRef.current = mr;
        setRecording(true);
      } catch(e) { console.error(e); }
  };

  const stopRecordingWav = () => {
      if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
        mediaRecorderRef.current.stop();
      }
      if (mediaStreamRef.current) {
        mediaStreamRef.current.getTracks().forEach((t) => t.stop());
      }
  };
  
  const toggleAutoConversation = () => {
    if (autoMode) {
        setAutoMode(false);
        window.speechSynthesis.cancel();
        message.info("ÄÃ£ dá»«ng cháº¿ Ä‘á»™ há»™i thoáº¡i.");
    } else {
        setAutoMode(true);
        // Khi báº­t cháº¿ Ä‘á»™ há»™i thoáº¡i, xÃ³a cÃ¢u máº«u Ä‘i Ä‘á»ƒ nÃ³i tá»± do
        setTargetSentence('');
        message.success("Báº¯t Ä‘áº§u há»™i thoáº¡i. HÃ£y nÃ³i gÃ¬ Ä‘Ã³!");
        startLiveRecognition();
    }
  };

  return (
    <Card style={{ maxWidth: 900, margin: '20px auto' }}>
      <div style={{display: 'flex', justifyContent: 'space-between', alignItems: 'center'}}>
        <h2>Luyá»‡n nÃ³i AI</h2>
        <Space>
            {/* ğŸ‘‡ NÃºt láº¥y máº«u cÃ¢u má»›i */}
            <Button icon={<BulbOutlined />} onClick={getSampleSentence} disabled={recording || autoMode}>
                Láº¥y máº«u cÃ¢u
            </Button>
            <Button 
                type={autoMode ? "primary" : "default"} 
                danger={autoMode}
                icon={<CommentOutlined />}
                onClick={toggleAutoConversation}
            >
                {autoMode ? "Dá»«ng ráº£nh tay" : "Ráº£nh tay"}
            </Button>
        </Space>
      </div>

      {/* ğŸ‘‡ Hiá»ƒn thá»‹ cÃ¢u máº«u to rÃµ Ä‘á»ƒ Ä‘á»c */}
      {targetSentence && (
          <div style={{ margin: '15px 0', padding: '15px', background: '#e6f7ff', border: '1px dashed #1890ff', borderRadius: 8, textAlign: 'center' }}>
              <div style={{fontSize: 12, color: '#666', marginBottom: 5}}>HÃ£y báº¥m Mic vÃ  Ä‘á»c to cÃ¢u sau:</div>
              <div style={{fontSize: 20, fontWeight: 'bold', color: '#0050b3'}}>{targetSentence}</div>
          </div>
      )}

      <div style={{ minHeight: 240, maxHeight: 420, overflowY: 'auto', padding: 12, border: '1px solid #f0f0f0', borderRadius: 8, marginBottom: 12, background: '#fafafa' }}>
        {messages.map((item) => (
          <div key={item.id} style={{ marginBottom: 12, textAlign: item.from === 'user' ? 'right' : 'left' }}>
            <div style={{ 
                display: 'inline-block',
                padding: '8px 12px', 
                borderRadius: 8, 
                background: item.from === 'user' ? '#1890ff' : (item.from === 'ai' ? '#fff' : '#eee'),
                color: item.from === 'user' ? '#fff' : '#333',
                border: item.from === 'ai' ? '1px solid #ddd' : 'none',
                maxWidth: '80%'
            }}>
                <div style={{fontWeight: 'bold', fontSize: 10, marginBottom: 2, opacity: 0.8}}>
                    {item.from === 'user' ? 'Báº¡n' : (item.from === 'ai' ? 'AI' : 'Há»‡ thá»‘ng')}
                </div>
                {item.text}
            </div>
          </div>
        ))}
      </div>

      <Space style={{ marginTop: 12, width: '100%' }}>
        <TextArea rows={2} value={input} onChange={(e) => setInput(e.target.value)} placeholder="Nháº­p tin nháº¯n..." />
      </Space>

      <Space style={{ marginTop: 12, flexWrap: 'wrap' }}>
        <Button type="primary" icon={<SendOutlined />} onClick={() => sendText(input)} disabled={!input.trim()}>Gá»­i</Button>
        
        <Button 
            type={recording && !autoMode ? 'default' : 'dashed'} 
            danger={recording && !autoMode} 
            icon={<AudioOutlined />} 
            onClick={() => (recording ? stopRecordingWav() : startRecordingWav())}
            disabled={autoMode} 
        >
          {recording && !autoMode ? 'Dá»«ng ghi Ã¢m' : transcribing ? 'Äang cháº¥m Ä‘iá»ƒm...' : 'Äá»c & Cháº¥m Ä‘iá»ƒm'}
        </Button>

        <Button onClick={() => startLiveRecognition()} icon={<DownCircleOutlined />} disabled={autoMode || recording}>
            Chat nhanh
        </Button>

        <Button onClick={() => window.speechSynthesis.cancel()}>Táº¯t tiáº¿ng</Button>
      </Space>

      {lastAssessment && (
        <Card style={{ marginTop: 14, background: '#f6ffed', borderColor: '#b7eb8f' }}>
          <h3>ğŸ“ Káº¿t quáº£ phÃ¡t Ã¢m</h3>
          <div>ÄÃ¡nh giÃ¡: <b>{lastAssessment.level}</b> - Äiá»ƒm sá»‘: <b style={{fontSize: 18, color: 'green'}}>{lastAssessment.overallScore?.toFixed(0)}/100</b></div>
          <div style={{ marginTop: 8 }}>
            {lastAssessment.words && lastAssessment.words.map((w: any, idx: number) => (
                <span key={idx} style={{ 
                  display: 'inline-block', marginRight: 6, marginBottom: 6, padding: '2px 6px', borderRadius: 4,
                  fontSize: 16,
                  background: w.accuracyScore >= 80 ? '#d9f7be' : w.accuracyScore >= 60 ? '#fff1b8' : '#ffccc7',
                  color: w.accuracyScore < 60 ? '#cf1322' : 'inherit',
                  textDecoration: w.accuracyScore < 60 ? 'underline' : 'none'
                }} title={`Score: ${w.accuracyScore} - Error: ${w.errorType}`}>
                  {w.word}
                </span>
              ))}
          </div>
        </Card>
      )}
    </Card>
  );
}